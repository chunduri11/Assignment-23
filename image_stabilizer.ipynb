{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/38/60de02a4c9013b14478a3f681a62e003c7489d207160a4d7df8705a682e7/opencv_python-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (28.3MB)\n",
      "\u001b[K     |████████████████████████████████| 28.3MB 893kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting numpy>=1.14.5 (from opencv-python)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/af/4fc72f9d38e43b092e91e5b8cb9956d25b2e3ff8c75aed95df5569e4734e/numpy-1.17.4-cp37-cp37m-manylinux1_x86_64.whl (20.0MB)\n",
      "\u001b[K     |████████████████████████████████| 20.0MB 9.8MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.17.4 opencv-python-4.1.2.30\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-66cea766e46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "import math, sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0,6.0)\n",
    "matplotlib.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "RESIZE_HEIGHT = 480\n",
    "#NUM_FRAMES_FOR_FPS = 100\n",
    "NUM_FRAMES_FOR_FPS = 309\n",
    "SKIP_FRAMES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the intereye distance.\n",
    "def interEyeDistance(predict):\n",
    "  leftEyeLeftCorner = (predict[36].x, predict[36].y)\n",
    "  rightEyeRightCorner = (predict[45].x, predict[45].y)\n",
    "  distance = cv2.norm(np.array(rightEyeRightCorner) - np.array(leftEyeLeftCorner))\n",
    "  distance = int(distance)\n",
    "  return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "winName = \"Stabilized facial landmark detector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoFileName = \"unstabilized_points_video.avi\"\n",
    "\n",
    "# Initializing video capture object.\n",
    "cap = cv2.VideoCapture(videoFileName)\n",
    "\n",
    "if(cap.isOpened()==False):\n",
    "  print(\"Unable to load video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = 101\n",
    "maxLevel = 10\n",
    "fps = 35.0\n",
    "# Grab a frame\n",
    "ret,imPrev = cap.read()\n",
    "imGrayPrev = cv2.cvtColor(imPrev, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the size of the image.\n",
    "size = imPrev.shape[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "landmarkDetector = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the parameters\n",
    "points=[]\n",
    "pointsPrev=[]\n",
    "pointsDetectedCur=[]\n",
    "pointsDetectedPrev=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeDistanceNotCalculated = True\n",
    "eyeDistance = 0\n",
    "isFirstFrame = True\n",
    "# Initial value, actual value calculated after 100 frames\n",
    "fps = 10\n",
    "showStabilized = True\n",
    "count =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face detected\n",
      "248\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n",
      "face detected\n",
      "248\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "C:\\ci\\opencv_1512688052760\\work\\modules\\imgproc\\src\\color.cpp:11016: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-aef9f55c92cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# Grab a frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[0mimDlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m   \u001b[1;31m# COnverting to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[0mimGray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\ci\\opencv_1512688052760\\work\\modules\\imgproc\\src\\color.cpp:11016: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "  if (count==0):\n",
    "    t = cv2.getTickCount()\n",
    "\n",
    "  # Grab a frame\n",
    "  ret,im = cap.read()\n",
    "  imDlib = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "  # COnverting to grayscale\n",
    "  imGray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "  height = im.shape[0]\n",
    "  IMAGE_RESIZE = float(height)/RESIZE_HEIGHT\n",
    "  # Resize image for faster face detection\n",
    "  imSmall = cv2.resize(im, None, fx=1.0/IMAGE_RESIZE, fy=1.0/IMAGE_RESIZE,interpolation = cv2.INTER_LINEAR)\n",
    "  imSmallDlib = cv2.cvtColor(imSmall, cv2.COLOR_BGR2RGB)\n",
    "  # Skipping the frames for faster processing\n",
    "  if (count % SKIP_FRAMES == 0):\n",
    "    faces = detector(imSmallDlib,0)\n",
    "\n",
    "  # If no face was detected\n",
    "  if len(faces)==0:\n",
    "    print(\"No face detected\")\n",
    "\n",
    "  # If faces are detected, iterate through each image and detect landmark points\n",
    "  else:\n",
    "    for i in range(0,len(faces)):\n",
    "      print(\"face detected\")\n",
    "      # Face detector was found over a smaller image.\n",
    "      # So, we scale face rectangle to correct size.\n",
    "      newRect = dlib.rectangle(int(faces[i].left() * IMAGE_RESIZE),\n",
    "        int(faces[i].top() * IMAGE_RESIZE),\n",
    "        int(faces[i].right() * IMAGE_RESIZE),\n",
    "        int(faces[i].bottom() * IMAGE_RESIZE))\n",
    "      \n",
    "      # Detect landmarks in current frame\n",
    "      landmarks = landmarkDetector(imDlib, newRect).parts()\n",
    "      \n",
    "      # Handling the first frame of video differently,for the first frame copy the current frame points\n",
    "      \n",
    "      if (isFirstFrame==True):\n",
    "        pointsPrev=[]\n",
    "        pointsDetectedPrev = []\n",
    "        [pointsPrev.append((p.x, p.y)) for p in landmarks]\n",
    "        [pointsDetectedPrev.append((p.x, p.y)) for p in landmarks]\n",
    "\n",
    "      # If not the first frame, copy points from previous frame.\n",
    "      else:\n",
    "        pointsPrev=[]\n",
    "        pointsDetectedPrev = []\n",
    "        pointsPrev = points\n",
    "        pointsDetectedPrev = pointsDetectedCur\n",
    "\n",
    "      # pointsDetectedCur stores results returned by the facial landmark detector\n",
    "      # points stores the stabilized landmark points\n",
    "      points = []\n",
    "      pointsDetectedCur = []\n",
    "      [points.append((p.x, p.y)) for p in landmarks]\n",
    "      [pointsDetectedCur.append((p.x, p.y)) for p in landmarks]\n",
    "\n",
    "      # Convert to numpy float array\n",
    "      pointsArr = np.array(points,np.float32)\n",
    "      pointsPrevArr = np.array(pointsPrev,np.float32)\n",
    "\n",
    "      # If eye distance is not calculated before\n",
    "      if eyeDistanceNotCalculated:\n",
    "        eyeDistance = interEyeDistance(landmarks)\n",
    "        print(eyeDistance)\n",
    "        eyeDistanceNotCalculated = False\n",
    "\n",
    "      if eyeDistance > 100:\n",
    "          dotRadius = 3\n",
    "      else:\n",
    "        dotRadius = 2\n",
    "\n",
    "      print(eyeDistance)\n",
    "      sigma = eyeDistance * eyeDistance / 400\n",
    "      s = 2*int(eyeDistance/4)+1\n",
    "\n",
    "      #  Set up optical flow params\n",
    "      lk_params = dict(winSize  = (s, s), maxLevel = 5, criteria = (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, 20, 0.03))\n",
    "      # Python Bug. Calculating pyramids and then calculating optical flow results in an error. So directly images are used.\n",
    "      # ret, imGrayPyr= cv2.buildOpticalFlowPyramid(imGray, (winSize,winSize), maxLevel)\n",
    "\n",
    "      pointsArr,status, err = cv2.calcOpticalFlowPyrLK(imGrayPrev,imGray,pointsPrevArr,pointsArr,**lk_params)\n",
    "      \n",
    "\n",
    "      # Converting to float\n",
    "      pointsArrFloat = np.array(pointsArr,np.float32)\n",
    "\n",
    "      # Converting back to list\n",
    "      points = pointsArrFloat.tolist()\n",
    "\n",
    "      # Final landmark points are a weighted average of\n",
    "      # detected landmarks and tracked landmarks\n",
    "      for k in range(0,len(landmarks)):\n",
    "        d = cv2.norm(np.array(pointsDetectedPrev[k]) - np.array(pointsDetectedCur[k]))\n",
    "        alpha = math.exp(-d*d/sigma)\n",
    "        points[k] = (1 - alpha) * np.array(pointsDetectedCur[k]) + alpha * np.array(points[k])\n",
    "\n",
    "      # Drawing over the stabilized landmark points\n",
    "      if showStabilized is True:\n",
    "        for p in points:\n",
    "          cv2.circle(im,(int(p[0]),int(p[1])),dotRadius, (255,0,0),-1)\n",
    "      else:\n",
    "        for p in pointsDetectedCur:\n",
    "          cv2.circle(im,(int(p[0]),int(p[1])),dotRadius, (0,0,255),-1)\n",
    "\n",
    "      isFirstFrame = False\n",
    "      count = count+1\n",
    "\n",
    "      # Calculating the fps value\n",
    "      if ( count == NUM_FRAMES_FOR_FPS):\n",
    "        t = (cv2.getTickCount()-t)/cv2.getTickFrequency()\n",
    "        fps = NUM_FRAMES_FOR_FPS/t\n",
    "        count = 0\n",
    "        isFirstFrame = True\n",
    "\n",
    "      # Display the landmarks points\n",
    "      cv2.putText(im, \"{:.1f}-fps\".format(fps), (50, size[0]-50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255), 3,cv2.LINE_AA)\n",
    "      cv2.imshow(winName, im)\n",
    "      plt.imsave(\"stabilized/frame\" + str(count) + '.jpg', im)\n",
    "      #key = cv2.waitKey(25) & 0xFF\n",
    "\n",
    "      # Use spacebar to toggle between Stabilized and Unstabilized version.\n",
    "      #if key==32:\n",
    "      #  showStabilized = not showStabilized\n",
    "\n",
    "      # Stop the program.\n",
    "      #if key==27:\n",
    "      #  sys.exit()\n",
    "      # Getting ready for next frame\n",
    "      imPrev = im\n",
    "      imGrayPrev = imGray\n",
    "\n",
    "cv2.destroyAllwindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
